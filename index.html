<!DOCTYPE html>
<html lang="en">

<!--Web Title Shown-->
<head>
    <title>Shuyue Jia 贾舒越</title>
    
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="keywords" content="Shuyue Jia, Shuyue, shuyue, shuyue jia, jia shuyue, jiashuyue, 贾舒越, 舒越, 舒越贾, 贾 舒越, 舒越 贾, shuyu jia, jia shuyu, 舒, 越, 贾, 贾舒, 贾越, 贾 舒 越, SHUYUE JIA, SHUYUE, JIA SHUYUE, JIASHUYUE, SHU, YUE, JIA, JIASHU, JIA SHU, JIA SHU YUE, Bruce Jia, Bruce, Bruce Shuyue Jia, Bruce Shuyue, Bruce Shuyue JIA, SHUYUE JIA, SHUYUE, JIA SHUYUE, JIASHUYUE, SHU, YUE, JIA, JIASHU, JIA SHU, JIA SHU YUE">
    <meta name="author" content="Shuyue Jia">
    <meta name="description" content="This is Shuyue Jia's Homepage! Reference: Shuyue Jia, Shuyue, shuyue, shuyue jia, jia shuyue, jiashuyue, 贾舒越, 舒越, 舒越贾, 贾 舒越, 舒越 贾, shuyu jia, jia shuyu, 舒, 越, 贾, 贾舒, 贾越, 贾 舒 越, SHUYUE JIA, SHUYUE, JIA SHUYUE, JIASHUYUE, SHU, YUE, JIA, JIASHU, JIA SHU, JIA SHU YUE, Bruce Jia, Bruce, Bruce Shuyue Jia, Bruce Shuyue, Bruce Shuyue JIA, SHUYUE JIA, SHUYUE, JIA SHUYUE, JIASHUYUE, SHU, YUE, JIA, JIASHU, JIA SHU, JIA SHU YUE">
    <meta name="google-site-verification" content="UZ7grdeibwJYn35EsW-Yp0Ky7_vuMG45bHI1kki15H0" />
    <meta name="baidu-site-verification" content="WJpwHTPWUq" />
  
    <style>
      div{
        line-height:28px;
      }
    </style>
    
    <link rel="shortcut icon" href="Google.ico">
    <link href="https://fonts.googleapis.com/css?family=Inconsolata:400,700" rel="stylesheet" type="text/css">
    <link rel="alternate" type="application/rss+xml" title="Shuyue Jia RSS" href="/feed.xml" />
    <link rel="stylesheet" href="/css/main.css">
    <link href="https://fonts.googleapis.com/css?family=Lato" rel="stylesheet" type="text/css">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.1/css/all.css" integrity="sha384-50oBUHEmvpQ+1lW4y57PTFmhCaXp0ML5d60M1M7uH2+nqUivzIebhndOJK28anvf" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css">
    <link rel="stylesheet" href="css/css/academicons.min.css" />
    <link href="css/main.css" rel="stylesheet" type="text/css">
</head>

<style type="text/css">
    p{
      text-align:justify;  
    }
    
    p i{
      display:inline-block;
      width:100%;
    }
  
  ul{
    text-align:justify;  
  }
  
  ul i{
    display:inline-block;
    width:100%;
  }
</style>

<!--Main Information-->
<body>
<!--Title-->
<div class="wrapper">
	<div class="navbar container">
		<a id="author-name" class="alignable pull-left" style="text-decoration:none">Shuyue Jia</a>
		<a id="blog" class="alignable pull-right" style="text-decoration:none" href="https://shuyuej.com/blog"> Blog</a>
	</div>

	<div style="clear:both"></div>

<hr>

<div class="container content">

<!--Short Bio Information-->
<h2 id="about-me">Bio</h2>

<p><img class="profile-picture" src="./imgs/Marathon_Profile.jpg" /></p>
  
<p>
  I am an M.Phil. student in Computer Science at the <a href="https://www.cityu.edu.hk/">City University of Hong Kong</a>, supervised by Dr. Shiqi Wang. Prior to joining CityU, I received my bachelor's degree at the <a href="http://www.neepu.edu.cn/">Northeast Electric Power University</a> in Jilin, China, under the supervision of Prof. Yimin Hou and Dr. Jinglei Lv.
  
  <br />
  <br />
  During my studies, I interned at the Computer Vision team of <a href="https://research.samsung.com/src-b"> Samsung Research</a> in Beijing and the Natural Language Processing team of <a href="https://www.philips.com/a-w/about/innovation/innovation-hubs.html">Philips Research</a> in Shanghai. In summer 2017, I attended a summer school at the <a href="https://uci.edu/">University of California, Irvine</a> in the United States.
  
  <br />
  <br />
  
  My research interests mainly lie in Image and Video Processing and Computer Vision. Some of my paper survey and presentations can be found
  
  <br />
  
  <details>
      <summary style="outline:none">here</summary>
      
      <p>Graph Neural Network (GNN)</p>
        <li><a href="./files/Dynamic-GCN-Survey.pdf"> <i class="fab fa fa-file-pdf-o" style="text-decoration:none"></i> Dynamic Graph Convolutional Neural Networks Survey</a></li>
        <li><a href="./files/GCNs-Net.pdf"> <i class="fab fa fa-file-pdf-o"></i> Graph Convolutional Neural Networks (Chebyshev Approximation)</a></li>
      
      <p>Natural Language Processing (NLP)</p>
        <li><a href="./files/Graph-Matching-Paper-Survey.pdf"> <i class="fab fa fa-file-pdf-o"></i> Graph Matching</a></li>
        <li><a href="./files/NMT-Subword-Unites.pdf"> <i class="fab fa fa-file-pdf-o"></i> Sub-word BPE Algorithm for NMT</a></li>
        <li><a href="./files/Concept-Matching.pdf"> <i class="fab fa fa-file-pdf-o"></i> Concept Matching for Medical Terms</a></li>

      <p>Computer Vision (CV)</p>
        <li><a href="./files/Model-Compression-Acceleration.pdf"> <i class="fab fa fa-file-pdf-o"></i> Deep Learning Models Compression and Acceleration</a></li>
        <li><a href="./files/Spatial-Sparse-CNNs.pdf"> <i class="fab fa fa-file-pdf-o"></i> 3D Human Pose Estimation and Human Body Reconstruction</a></li>
        <li><a href="./files/YOLO.pdf"> <i class="fab fa fa-file-pdf-o"></i> YOLO Object Detection</a></li>

      <p>Other Tutorials</p>
        <li><a href="./files/Server.pdf"> <i class="fab fa fa-file-pdf-o"></i> Usage of Cloud Server and Setting-up</a></li>
        <li><a href="./files/Python.pdf"> <i class="fab fa fa-file-pdf-o"></i> Python Environment Setting-up</a></li>
        <li><a href="./files/TensorFlow.pdf"> <i class="fab fa fa-file-pdf-o"></i> TensorFlow for Deep Learning</a></li>
        <li><a href="./files/Crypto-currency-Return-and-Price-Prediction-with-Machine-Learning.pdf"> <i class="fab fa fa-file-pdf-o"></i> Crypto currency Return and Price Prediction with Machine Learning</a></li>
        <li><a href="./files/PySpark-and-Horovod.pdf"> <i class="fab fa fa-file-pdf-o"></i> Big Data Parallel Processing by PySpark and Horovod Distributed Deep Learning</a></li>
        
      <p>Other Resources</p>
      <li><a href="./resources/How_to_Write_Good_Research_Articles_Xiaohua_JIA.pdf"> <i class="fab fa fa-file-pdf-o"></i> How to Write Good Research Articles by Prof. Xiaohua JIA</a></li>
      <li><a href="./resources/How_to_Use_IEEEtran_LaTeX_Class.pdf"> <i class="fab fa fa-file-pdf-o"></i> How to Use the IEEEtran LaTeX Class</a></li>
      <li><a href="./resources/IEEE-Editing-Mathematics.pdf"> <i class="fab fa fa-file-pdf-o"></i> IEEE Editing Mathematics Guide (Standard)</a></li>
      <li><a href="./resources/IEEE_Math_Typesetting_Guide.pdf"> <i class="fab fa fa-file-pdf-o"></i> IEEE Math Typesetting Guide (LaTex)</a></li>
      <li><a href="./resources/Formula_Comma_IEEE.pdf"> <i class="fab fa fa-file-pdf-o"></i> IEEE Formula Comma or Period</a></li>
      <li><a href="./resources/IEEE-Reference-Guide-2021.pdf"> <i class="fab fa fa-file-pdf-o"></i> IEEE Reference Guide (2021)</a></li>
      <li><a href="https://woodward.library.ubc.ca/research-help/journal-abbreviations/"> <i class="fab fa fa-file-pdf-o"></i> Science and Engineering Journal Abbreviations</a></li>
      <li><a href="https://libguides.uwf.edu/c.php?g=848362&p=6073747"> <i class="fab fa fa-file-pdf-o"></i> Standard abbreviations used in the IEEE Reference list</a></li>
      <li><a href="./resources/IEEE-Editorial-Style-Manual-2021.pdf"> <i class="fab fa fa-file-pdf-o"></i> IEEE Editorial Style Manual (2021)</a></li>
      <li><a href="./resources/IEEE_Citation_Examples.pdf"> <i class="fab fa fa-file-pdf-o"></i> IEEE Citation Examples</a></li>
      <li><a href="./resources/Taiwan_Research.pdf"> <i class="fab fa fa-file-pdf-o"></i> 台灣研究者最專業的學術英文雜誌</a></li>
      <li><a href="./resources/JCR_2021.pdf"> <i class="fab fa fa-file-pdf-o"></i> InCites Journal Citation Reports (2021)</a></li>
      <li><a href="./resources/中国计算机学会CCF推荐国际学术会议和期刊目录_2019.pdf"> <i class="fab fa fa-file-pdf-o"></i> 中国计算机学会推荐国际学术会议和期刊目录 (2019)</a></li>
      <li><a href="./resources/中国科学院SCI分区表_2019.xls"> <i class="fab fa fa-file-pdf-o"></i> 中国科学院SCI分区表 (2019)</a></li>
      <li><a href="./resources/中科院国际期刊预警名单.pdf"> <i class="fab fa fa-file-pdf-o"></i> 中国科学院国际期刊预警名单</a></li>
      <li><a href="./resources/清华大学各院系重要国际学术会议目录_2018.pdf"> <i class="fab fa fa-file-pdf-o"></i> 清华大学各院系(学科)重要国际学术会议目录 (2018)</a></li>
    
    <p>Good Articles</p>
    <li><a href="./resources/Research_Life.pdf"> <i class="fab fa fa-file-pdf-o"></i> 文章千古事, 得失寸心知 by Prof. Song-Chun Zhu</a></li>
    <li><a href="./resources/Computer_Vision_History.pdf"> <i class="fab fa fa-file-pdf-o"></i> A Brief History of Computational Vision by Prof. Song-Chun Zhu</a></li>
    <li><a href="https://www.cs.virginia.edu/~robins/YouAndYourResearch.html"> <i class="fab fa fa-file-pdf-o"></i> You and Your Research by Prof. Richard Hamming</a></li>
    <li><a href="https://zhuanlan.zhihu.com/p/338193330"> <i class="fab fa fa-file-pdf-o"></i> Columbia University Ph.D. (CV Track) Summary by Prof. Mike Shou</a></li>

  </details>
  
  <br />
  
  Email: <a href="mailto:shuyuej@ieee.org">shuyuej@ieee.org</a>
  
  <br>
  
  <a href="https://scholar.google.com/citations?user=PfpEP60AAAAJ&hl=en"><i class="ai ai-google-scholar-square ai-1x"></i> Scholar</a>&nbsp
  <a href="https://github.com/SuperBruceJia"><i class="fab fa fa-github"></i> GitHub</a> 
  <iframe src="https://img.shields.io/github/followers/SuperBruceJia?label=follow&style=social" frameborder="0" scrolling="0" width="100px" height="20px"></iframe>
  <iframe src="https://img.shields.io/github/stars/SuperBruceJia?label=stars&style=social" frameborder="0" scrolling="0" width="100px" height="20px"></iframe>&nbsp
  
<!--  <a href="https://scholar.google.com/citations?user=PfpEP60AAAAJ&hl=en"><i class="ai ai-google-scholar-square ai-1x"></i> Scholar</a>&nbsp-->
<!--  <a href="./CV-Latex/ShuyueJia-CV.pdf"> <i class="fab fa fa-file-pdf-o"></i> Résumé</a>&nbsp-->
<!--  <a href="./Chinese-Resume/ShuyueJia-Chinese-Resume.pdf"> <i class="fab fa fa-file-pdf-o"></i> 简历</a>&nbsp-->
<!--  <a href="https://github.com/SuperBruceJia"><i class="fab fa fa-github"></i> GitHub</a> -->
<!--  <iframe src="https://img.shields.io/github/followers/SuperBruceJia?label=follow&style=social" frameborder="0" scrolling="0" width="100px" height="20px"></iframe>-->
<!--  <iframe src="https://img.shields.io/github/stars/SuperBruceJia?label=stars&style=social" frameborder="0" scrolling="0" width="100px" height="20px"></iframe>&nbsp-->
  <!--  <?php $lang="en"; $userid="PfpEP60AAAAJ"; $pagesize="100"; include 'css/curl.php'; ?>-->
  <!--  <?php include 'css/citation_chart.php'; ?> -->
  <!--  &nbsp-->
  
</p>

<!--Latest News-->
<h2 id="news">News</h2>

<ul style="list-style:none; margin:0; padding:0">
  <li>
    <li>
      <strong>Aug 2022</strong> One Paper NLNet accepted by <em>IEEE MMSP</em>
      <iframe
        src="https://img.shields.io/github/stars/SuperBruceJia/NLNet-IQA?style=social"
        frameborder="0" scrolling="0" width="85px" height="20px">
      </iframe>
      <iframe
        src="https://img.shields.io/github/forks/SuperBruceJia/NLNet-IQA?style=social"
        frameborder="0" scrolling="0" width="85px" height="20px">
      </iframe>.
    </li>
    <li><strong>Apr 2022</strong> CV Intern at <a href="https://research.samsung.com/src-b"> Samsung Research</a>, Beijing. (Supervisor: Dr. Hui Zhang)</li>
    <strong>Dec 2021</strong> One Paper <a href="https://www.frontiersin.org/article/10.3389/fbioe.2021.706229"> BiLSTM-GCNs</a> accepted by <em>Frontiers in Bioengineering and Biotechnology</em>.</li>
  <li><strong>Jul 2020</strong> NLP Intern at <a href="https://www.philips.com/a-w/about/innovation/innovation-hubs.html"> Philips Research</a>, Shanghai. (Supervisor: Dr. Shuang Zhou)</li>
  <li>
    <strong>Apr 2020</strong> Open Source <a href="https://github.com/SuperBruceJia/EEG-DL"> EEG-DL</a>, 
    a Deep Learning (DL) library written by TensorFlow for EEG Signals Classification
    <iframe
      src="https://img.shields.io/github/stars/SuperBruceJia/EEG-DL?style=social" 
      frameborder="0" scrolling="0" width="90px" height="20px">
    </iframe>
    <iframe
      src="https://img.shields.io/github/forks/SuperBruceJia/EEG-DL?style=social" 
      frameborder="0" scrolling="0" width="100px" height="20px">
    </iframe>.
  </li>
  <li>
    <strong>Feb 2020</strong> One Paper<a href="https://iopscience.iop.org/article/10.1088/1741-2552/ab4af6/meta"> ESI-CNNs</a> accepted by <em>Journal of Neural Engineering</em> 
    <iframe
      src="https://img.shields.io/github/stars/SuperBruceJia/EEG-Motor-Imagery-Classification-CNNs-TensorFlow?style=social"
      frameborder="0" scrolling="0" width="85px" height="20px">
    </iframe>
    <iframe
      src="https://img.shields.io/github/forks/SuperBruceJia/EEG-Motor-Imagery-Classification-CNNs-TensorFlow?style=social"
      frameborder="0" scrolling="0" width="85px" height="20px">
    </iframe>.
  </li>
<!--  <li><strong>Jun 2019</strong> Summer NLP Intern at <a href="https://www.cs.tsinghua.edu.cn/csen/"> Tsinghua University</a>, Beijing.</li>-->
</ul>

<!--Recent Publications-->
<h2 id="publications">Publications</h2>

<ol>
  <li>
    <div style="float:left;">
      <font color="#00066f">No-reference Image Quality Assessment via Non-local Dependency Modeling</font>
    </div><br>
    <div style="float:left;">
      Shuyue Jia, Baoliang Chen, Dingquan Li, Shiqi Wang
    </div>
    <div style="float:right;">
      <a href="https://github.com/SuperBruceJia/NLNet-IQA"><i class="fa fa-github"></i> Codes</a>
    </div>
    <em><br>IEEE 24th International Workshop on Multimedia Signal Processing</em>, 2022.
    <details>
      <summary style="outline:none">See More</summary>
      <ul>
        A no-reference image quality assessment method based on non-local features learned by a graph neural network (GNN). The proposed quality assessment framework is rooted in the view that the human visual system perceives image quality with long-dependency constructed among different regions, inspiring us to explore the non-local interactions in quality prediction.
        <div style="text-align:center">
          <img width="99%device-width" src="./imgs/Picture5.jpg" alt="NL-Net">
        </div>
      </ul>
    </details>
  </li>
  
  <hr>
  
  <li>
    <div style="float:left;">
      <font color="#00066f">Deep Feature Mining via Attention-based BiLSTM-GCN for Human Motor Imagery Recognition</font>
    </div><br>
    <div style="float:left;">
      Yimin Hou, <strong>Shuyue Jia *</strong>, Xiangmin Lun, Shu Zhang, Tao Chen, Fang Wang, Jinglei Lv
    </div>
    <div style="float:right;">
      <a href="https://github.com/SuperBruceJia/EEG-DL"><i class="fa fa-github"></i> Codes</a>
      <a href="https://www.frontiersin.org/article/10.3389/fbioe.2021.706229"><i class="fab fa fa-file-pdf-o"></i> Paper</a>
    </div>
    <em><br>Frontiers in Bioengineering and Biotechnology</em>, 2022.
    <details>
      <summary style="outline:none">See More</summary>
      <ul>
        We introduced a novel approach that combined Attention-based BiLSTM with the Graph Convolutional Neural Network (Graph CNN / GCN).
        <ul>
          <li>
            Open Source <a href="https://github.com/SuperBruceJia/EEG-DL">EEG-DL</a>, a Deep Learning (DL) library written by TensorFlow for EEG Tasks (Signals) Classification.<br>
          </li>
          <li>
            Attention-based BiLSTM was firstly used to extract features from raw EEG signals. The followed GCN model classified the features of four EEG Motor Imagery (MI) tasks, imagining left fist, right fist, both fists, and both feet.
          </li>
          <li>
            98.81% and 94.64% accuracies have been achieved for the individual subject and a group of 20 subjects.
          </li>
          <li>
            Benchmark Dataset: <a href="https://archive.physionet.org/pn4/eegmmidb/">EEG Motor Movement/Imagery Dataset</a>.
          </li>
        </ul>
        <div>
          <div style="text-align:center">
            <img width="99%device-width" src="./imgs/Picture3.jpg" alt="Project3.1">
            <img width="99%device-width" src="./imgs/Picture4.jpg" alt="Project3.2">
          </div>
        </div>
      </ul>
    </details>
  </li>
  
  <hr>
  
  <li>
    <div style="float:left;">
      <font color="#00066f"> 
        A Novel Approach of Decoding EEG Four-Class Motor Imagery Tasks via Scout ESI and CNN
      </font>
    </div>
    <div style="float:right;">
      <a href="https://github.com/SuperBruceJia/EEG-Motor-Imagery-Classification-CNNs-TensorFlow"><i class="fab fa fa-github"></i> Codes</a>
      <a href="https://iopscience.iop.org/article/10.1088/1741-2552/ab4af6/meta"><i class="fab fa fa-file-pdf-o"></i> Paper</a>
    </div><br>
    Yimin Hou, Lu Zhou, <strong>Shuyue Jia</strong>, Xiangmin Lun
    <em><br>Journal of Neural Engineering</em>, 2020.
    <details>
      <summary style="outline:none">See More</summary>
      <ul>
        We presented a novel approach that could potentially improve the current stroke rehabilitation strategies by implementing a deep learning approach for an Electroencephalogram (EEG) based on MI Brain-Computer Interface System.
        <ul>
          <li>
            Constructed 6 convolutional layers, 2 max-pooling layers, and 3 FC layers CNNs for four-class motor imagery classification through TensorFlow, with 50% dropout (spatial dropout after every Conv layer and regular dropout for FC layers) &ndash; 11.44% accuracy improvement, batch normalization (BN) &ndash; 10.15% improvement, and Short-cut Connection &ndash; 1.76% improvement to prevent overfitting, and achieved SOTA results: 94.50% accuracy on scout R5, 94.54% at subject level, and 96% for left fist prediction.
          </li>
          <li>
            Took charge of DNNs design, including methods comparisons, such as MLPs, CNNs, RNNs, and LSTMs,
            classification results calculations, and programming. 10 and 14 subjects&rsquo; data were utilized (19,320 and
            27,048 samples in the experiments)
          </li>
          <li>
            Benchmark Dataset: <a href="https://archive.physionet.org/pn4/eegmmidb/"> EEG Motor Movement/Imagery Dataset</a>.
          </li>
        </ul>
        <div>
          <div style="text-align:center">
            <img width="99%device-width" src="./imgs/Picture1.jpg" alt="EEG-CNN">
          </div>
        </div>
      </ul>
    </details>
  
  </li>
  
  <!--  ####################################################################################################################################################-->
  <hr>
  
  <li>
    <div style="float:left;">
      <font color="#00066f">
        GCNs-Net: A Graph Convolutional Neural Network Approach for Decoding Time-resolved EEG Motor Imagery Signals
      </font>
    </div><br>
    <div style="float:left;">
      Yimin Hou, <strong>Shuyue Jia *</strong>, Xiangmin Lun, Shu Zhang, Tao Chen, Fang Wang, Jinglei Lv
    </div>
    <br>
    <div style="float:left;">
      <em>arXiv preprint arXiv:2006.08924</em>, 2022.
    </div>
    <div style="float:right;">
      <a href="./files/Dynamic-GCN-Survey.pdf"><i class="fa fa-file-powerpoint-o"></i> Dynamic GNN Survey</a>
      <a href="./files/GCNs-Net.pdf"><i class="fa fa-file-powerpoint-o"></i> Presentation</a>
      <a href="https://github.com/SuperBruceJia/EEG-DL"><i class="fa fa-github"></i> Codes</a>
      <a href="https://arxiv.org/abs/2006.08924"><i class="fab fa fa-file-pdf-o"></i> Paper</a>
    </div><br><br>
    <details>
      <summary style="outline:none">See More</summary>
      <ul>
        Based on the Graph Convolutional Neural Network (Graph CNN / GCN), the GCNs-Net was introduced, which filtered the EEG Motor Imagery (MI) signals considering the functional topological relationship of EEG electrodes.
        <ul>
          <li>
            At the subject and group level (subject-specific adaptation), 98.72% and 89.387% accuracy were achieved, respectively.
          </li>
          <li>
            Pearson&rsquo;s Matrix was applied to measure the correlations among channels, and represented the graph structure, i.e., graph weights and degrees.
          </li>
          <li>
            Benchmark Datasets: <a href="https://archive.physionet.org/pn4/eegmmidb/"> EEG Motor
              Movement/Imagery Dataset</a>, in which 20 ( a million samples), 50, 100 participants&rsquo; data were used, and the <a href="https://gin.g-node.org/robintibor/high-gamma-dataset">High-Gamma Dataset</a>, in which 14  participates' data were used.
          </li>
        </ul>
        <div>
          <div style="text-align:center">
            <img width="99%device-width" src="imgs/Picture2.jpg" alt="Project2">
          </div>
        </div>
      </ul>
    </details>
  </li>
    
  <hr>
  
  <li>
    <div style="float:left;">
      <font color="#00066f">
        Attention-based Graph ResNet for Motor Intent Detection from Raw EEG signals
      </font>
    </div><br>
    <div style="float:left;">
      <strong>Shuyue Jia *</strong>, Yimin Hou, Yan Shi, and Yang Li
    </div>
    <div style="float:right;">
      <a href="https://github.com/SuperBruceJia/EEG-DL"><i class="fa fa-github"></i> Codes</a>
      <a href="https://arxiv.org/abs/2007.13484"><i class="fab fa fa-file-pdf-o"></i> Paper</a>
    </div>
    <em><br>arXiv preprint arXiv:2007.13484</em>, 2022.
  </li>

  <hr>
  
  <li>
    <div style="float:left;">
      <font color="#00066f">
        Improving Performance: a Collaborative Strategy for the Multi-data Fusion of Electronic Nose and Hyperspectral to Track the Quality Difference of Rice
      </font>
    </div><br>
    <div style="float:left;">
      Yan Shi, Hangcheng Yuan, Chenao Xiong, <strong>Shuyue Jia</strong>, Jingjing Liu, and Hong Men
    </div>
    <div style="float:right;">
      <a href="https://www.sciencedirect.com/science/article/pii/S0925400521001143"><i class="fab fa fa-file-pdf-o"></i> Paper</a>
    </div>
    <em><br>Sensors &amp; Actuators: B. Chemical</em>, 2021.
  </li>

<hr>

</ol><ul><b>* denotes the Corresponding Author.</b></ul>

<!--Academic Services-->
<h2 id="Academic Services">Academic Services</h2>
<ol>
<!--	<li>-->
<!--<a href="https://publons.com/researcher/4330829/shuyue-jia/"><strong>Reviewer</strong></a> for <em>IEEE Journal of Biomedical and Health Informatics</em><br>-->
<!--  </li>-->
	<li><strong>Student Member</strong> of <em>IEEE</em></li>
</ol>

<!--Previous Awards-->
<h2 id="Selected Awards">Selected Awards</h2>

<ol>
<!--  <li>-->
<!--<div style="float:left;">-->
<!--  <font color="#00066f">-->
<!--    2021 Standard Chartered Hong Kong Marathon-->
<!--  </font>-->
<!--</div>-->
<!---->
<!--<br>-->
<!---->
<!--<details>-->
<!--  <summary style="outline:none">Ranking of Half Marathon Race: 318 / 6000 (01:38:14)</summary>-->
<!--  <div>-->
<!--    <div style="text-align:center">-->
<!--      <img width="99%device-width" src="./imgs/marathon2021.jpg" alt="marathon-2021">-->
<!--    </div>-->
<!--    <div style="text-align:center">-->
<!--      <img width="99%device-width" src="./imgs/cityu_marathon_2021.jpg" alt="marathon-2021">-->
<!--    </div>-->
<!--    <div style="text-align:center">-->
<!--      <img width="99%device-width" src="./imgs/cityu-deligation-2021.jpg" alt="marathon-2021">-->
<!--    </div>-->
<!--  </div>-->
<!--</details>-->
<!--  </li>-->
  
  <li>
    <div style="float:left;">
      <font color="#00066f">
        2019 Interdisciplinary Contest In Modeling
      </font>
    </div>
    <div style="float:right;">
      <a href="./files/ICM-2019.pdf"><i class="fab fa fa-file-pdf-o"></i> Thesis</a>
    </div>

    <br>

    <details>
        <summary style="outline:none">Honorable Mention</summary>
          <div>
            <div style="text-align:center">
              <img width="99%device-width" src="./imgs/ICM-2019.jpg" alt="ICM-2019">
            </div>
          </div>
    </details>
  </li>

  <li>
    <div style="float:left;">
      <font color="#00066f">
        2018 Mathematical Contest In Modeling (Jilin, China)
      </font>
    </div>

    <div style="float:right;">
      <a href="./files/MCM-2018.pdf"><i class="fab fa fa-file-pdf-o"></i> Thesis</a>
    </div>
    
    <br>

    <details>
        <summary style="outline:none">First Prize</summary>
          <div>
            <div style="text-align:center">
              <img width="99%device-width" src="./imgs/MCM-2018.jpg" alt="MCM">
            </div>
          </div>
    </details>
  </li>
  
  <li>
    <div style="float:left;">
      <font color="#00066f">
        2015 National High School Math League (China)
      </font>
    </div>
    
    <br>
    
    <details>
      <summary style="outline:none">Second Prize</summary>
      <div>
        <div style="text-align:center">
          <img width="99%device-width" src="./imgs/Math.jpg" alt="Math">
        </div>
      </div>
    </details>
  </li>
  
  <li>
    <div style="float:left;">
      <font color="#00066f">
        The 32nd Chinese Physics Olympiad (CPhO)
      </font>
    </div>
    
    <br>
    
    <details>
      <summary style="outline:none">Third Prize</summary>
      <div>
        <div style="text-align:center">
          <img width="99%device-width" src="./imgs/Physics.jpg" alt="Physics">
        </div>
      </div>
    </details>
  </li>

<!--  <li>-->
<!--<div style="float:left;">-->
<!--  <font color="#00066f">-->
<!--    2018 Interdisciplinary Contest In Modeling-->
<!--  </font>-->
<!--</div>-->
<!---->
<!--<div style="float:right;">-->
<!--  <a href="./files/ICM-2018.pdf"><i class="fab fa fa-file-pdf-o"></i> Thesis</a>-->
<!--</div>-->
<!---->
<!--<br>-->
<!---->
<!--<details>-->
<!--    <summary style="outline:none">Successful Participant</summary>-->
<!--      <div>-->
<!--        <div style="text-align:center">-->
<!--          <img width="99%device-width" src="./imgs/ICM-2018.jpg" alt="ICM-2018">-->
<!--        </div>-->
<!--      </div>-->
<!--</details>-->
<!--  </li>-->
  
<!--  <li>-->
<!--<div style="float:left;">-->
<!--  <font color="#00066f">-->
<!--    2017 Jilin City International Marathon-->
<!--  </font>-->
<!--</div>-->
<!---->
<!--<br>-->
<!---->
<!--<details>-->
<!--  <summary style="outline:none">Ranking of Half Marathon Race: 148 / 4000 (01:47:36)</summary>-->
<!--  <div>-->
<!--    <div style="text-align:center">-->
<!--      <img width="99%device-width" src="./imgs/marathon2017.jpg" alt="marathon-2017">-->
<!--    </div>-->
<!--  </div>-->
<!--</details>-->
<!--  </li>-->
  
<!--  <li>-->
<!--<div style="float:left;">-->
<!--  <font color="#00066f">-->
<!--    3000-meter Steeplechase (The 45th NEEPU Games)-->
<!--  </font>-->
<!--</div>-->
<!---->
<!--<br>-->
<!---->
<!--<details>-->
<!--  <summary style="outline:none">The Seventh Place</summary>-->
<!--  <div>-->
<!--    <div style="text-align:center">-->
<!--      <img width="99%device-width" src="./imgs/Steeplechase.jpg" alt="marathon-2017">-->
<!--    </div>-->
<!--  </div>-->
<!--</details>-->
<!--  </li>-->
  
</ol>

<br>
<br>

</div>
</div>
	
<hr>
<br>

</body>
  
<footer style="text-align:center">
  Last update: Mar 27th, 2022<br>
  <span>Copyright &copy;2020 Shuyue Jia</span>
</footer>

<br>
<br>
<br>
<br>
</html>
