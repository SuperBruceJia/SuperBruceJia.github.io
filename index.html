<!DOCTYPE html>
<html lang="en">

<!--Web Title Shown-->
<head>
    <title>Shuyue Jia 贾舒越</title>
	
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="keywords" content="Shuyue Jia, Shuyue, shuyue, shuyue jia, jia shuyue, jiashuyue, 贾舒越, 舒越, 舒越贾, 贾 舒越, 舒越 贾, shuyu jia, jia shuyu, 舒, 越, 贾, 贾舒, 贾越, 贾 舒 越, SHUYUE JIA, SHUYUE, JIA SHUYUE, JIASHUYUE, SHU, YUE, JIA, JIASHU, JIA SHU, JIA SHU YUE, ">
    <meta name="author" content="Shuyue Jia">
    <meta name="description" content="This is Shuyue Jia's Homepage! (Reference: Shuyue Jia, Shuyue, shuyue, shuyue jia, jia shuyue, jiashuyue, 贾舒越, 舒越, 舒越贾, 贾 舒越, 舒越 贾, shuyu jia, jia shuyu, 舒, 越, 贾, 贾舒, 贾越, 贾 舒 越, SHUYUE JIA, SHUYUE, JIA SHUYUE, JIASHUYUE, SHU, YUE, JIA, JIASHU, JIA SHU, JIA SHU YUE, )">
    <meta name="google-site-verification" content="UZ7grdeibwJYn35EsW-Yp0Ky7_vuMG45bHI1kki15H0" />
    <meta name="baidu-site-verification" content="WJpwHTPWUq" />
	
    <style>
      div{
        line-height:28px;
      }
    </style>
    
    <link href="https://fonts.googleapis.com/css?family=Inconsolata:400,700" rel="stylesheet" type="text/css">
    <link rel="alternate" type="application/rss+xml" title="Shuyue Jia RSS" href="/feed.xml" />
    <link rel="stylesheet" href="/css/main.css">
    <link href="https://fonts.googleapis.com/css?family=Lato" rel="stylesheet" type="text/css">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.1/css/all.css" integrity="sha384-50oBUHEmvpQ+1lW4y57PTFmhCaXp0ML5d60M1M7uH2+nqUivzIebhndOJK28anvf" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css">
    <link rel="stylesheet" href="css/css/academicons.min.css" />
	<link href="css/main.css" rel="stylesheet" type="text/css">
</head>

<!--Main Information-->
<body>
<!--Title-->
<div class="wrapper">
	<div class="navbar container">
		<a id="author-name" class="alignable pull-left" style="text-decoration:none"> Shuyue Jia 贾舒越</a>
		<a id="blog" class="alignable pull-right" style="text-decoration:none" href="https://shuyuej.com/blog"> Blog</a>
	</div>
	
	<div style="clear:both"></div>

<hr>

<div class="container content">

<!--Short Bio Information-->
<h2 id="about-me">Bio</h2>

<p><img class="profile-picture" src="./imgs/profile.jpg" /></p>

<p>
	I am a first-year M.Phil. student in Computer Science at <a href="https://www.cityu.edu.hk/">City University of Hong Kong</a>, where I am fortunate to be advised by <a href="https://www.cs.cityu.edu.hk/~shiqwang/">Dr. Shiqi Wang</a>. In summer 2017, I attended a summer school at <a href="https://uci.edu/">University of California, Irvine</a> in CA, USA. Prior to joining CityU, I received my bachelor's degree at <a href="http://www.neepu.edu.cn/">Northeast Electric Power University</a> in Jilin, China, supervised by <a href="https://ieeexplore.ieee.org/author/37290052900">Prof. Yimin Hou</a>.
  <br />
  <br />
 
  My research focuses on Computer Vision and Machine Learning, and my current concentration is Image Quality Assessment and Perceptual Optimization. I always aim to use what I have learned to bring a positive impact on people's lives.
  
  <br /> 
  <br />

  Some of my paper survey and presentations can be found

  <br />
  
  <details>
      <summary style="outline:none">here</summary>
      
      <p>Graph Neural Network (GNN)</p>
      	<li><a href="./files/Dynamic-GCN-Survey.pdf"> <i class="fab fa fa-file-pdf-o" style="text-decoration:none"></i> Dynamic Graph Convolutional Neural Networks Survey</a></li>
      	<li><a href="./files/GCNs-Net.pdf"> <i class="fab fa fa-file-pdf-o"></i> Graph Convolutional Neural Networks (Chebyshev Approximation)</a></li>
	  
      <p>Natural Language Processing (NLP)</p>
      	<li><a href="./files/Graph-Matching-Paper-Survey.pdf"> <i class="fab fa fa-file-pdf-o"></i> Graph Matching</a></li>
      	<li><a href="./files/NMT-Subword-Unites.pdf"> <i class="fab fa fa-file-pdf-o"></i> Sub-word BPE Algorithm for NMT</a></li>
      	<li><a href="./files/Concept-Matching.pdf"> <i class="fab fa fa-file-pdf-o"></i> Concept Matching for Medical Terms</a></li>

      <p>Computer Vision (CV)</p>
		<li><a href="./files/Model-Compression-Acceleration.pdf"> <i class="fab fa fa-file-pdf-o"></i> Deep Learning Models Compression and Acceleration</a></li>
      	<li><a href="./files/Spatial-Sparse-CNNs.pdf"> <i class="fab fa fa-file-pdf-o"></i> 3D Human Pose Estimation and Human Body Reconstruction</a></li>
      	<li><a href="./files/YOLO.pdf"> <i class="fab fa fa-file-pdf-o"></i> YOLO Object Detection</a></li>
	
      <p>Other Tutorials</p>
      	<li><a href="./files/Server.pdf"> <i class="fab fa fa-file-pdf-o"></i> Usage of Cloud Server and Setting-up</a></li>
      	<li><a href="./files/Python.pdf"> <i class="fab fa fa-file-pdf-o"></i> Python Environment Setting-up</a></li>
      	<li><a href="./files/TensorFlow.pdf"> <i class="fab fa fa-file-pdf-o"></i> TensorFlow for Deep Learning</a></li>
  </details>
  
  <br />
  
  Email: <a href="mailto:shuyuej@ieee.org">shuyuej@ieee.org</a> or <a href="mailto:shuyue.jia@my.cityu.edu.hk">shuyue.jia@my.cityu.edu.hk</a><br>
  
  <a href="https://scholar.google.com/citations?user=PfpEP60AAAAJ&hl=en&authuser=1"><i class="ai ai-google-scholar-square ai-1x"></i> Scholar</a> &nbsp
  <a href="./CV-Latex/ShuyueJia-CV.pdf"> <i class="fab fa fa-file-pdf-o"></i> Résumé</a> &nbsp
  <a href="https://github.com/SuperBruceJia"><i class="fab fa fa-github"></i> GitHub</a> 
  <iframe src="https://img.shields.io/github/followers/SuperBruceJia?label=follow&style=social" frameborder="0" scrolling="0" width="100px" height="20px"></iframe>
  <iframe src="https://img.shields.io/github/stars/SuperBruceJia?label=stars&style=social" frameborder="0" scrolling="0" width="100px" height="20px"></iframe>&nbsp
</p>

<!--Latest News-->
<h2 id="news">News</h2>

<ul style="list-style:none; margin:0; padding:0">
  <li><strong>Oct 2020</strong> Recommendation System Intern at <a href="https://www.tencent.com/en-us/about.html"> Tencent Video</a>, Beijing.</li>
  <li><strong>Jul 2020</strong> NLP Intern at <a href="https://www.philips.com/a-w/research/locations/shanghai.html"> Philips Research</a>, Shanghai.</li>
  <li>
    <strong>Apr 2020</strong> Open Source <a href="https://github.com/SuperBruceJia/EEG-DL"> EEG-DL</a>, 
    a Deep Learning (DL) library written by TensorFlow for EEG Signals Classification (Undergraduate Thesis Project)
    <iframe
      src="https://img.shields.io/github/stars/SuperBruceJia/EEG-DL?style=social" 
      frameborder="0" scrolling="0" width="90px" height="20px">
    </iframe>
    <iframe
      src="https://img.shields.io/github/forks/SuperBruceJia/EEG-DL?style=social" 
      frameborder="0" scrolling="0" width="100px" height="20px">
    </iframe>.
  </li>
  <li>
    <strong>Feb 2020</strong> <a href="https://iopscience.iop.org/article/10.1088/1741-2552/ab4af6/meta"> One Paper</a>
    accepted by <em>Journal of Neural Engineering</em> 
    <iframe
      src="https://img.shields.io/github/stars/SuperBruceJia/EEG-Motor-Imagery-Classification-CNNs-TensorFlow?style=social"
      frameborder="0" scrolling="0" width="85px" height="20px">
    </iframe>
    <iframe
      src="https://img.shields.io/github/forks/SuperBruceJia/EEG-Motor-Imagery-Classification-CNNs-TensorFlow?style=social"
      frameborder="0" scrolling="0" width="85px" height="20px">
    </iframe>.
  </li>
  <li><strong>Jun 2019</strong> Summer Intern at <a href="http://www.csai.tsinghua.edu.cn/"> Tsinghua University</a>, Beijing.</li>
</ul>

<!--Recent Publications-->
<h2 id="publications">Publications</h2>

<ol>
  <li>
    <div style="float:left;">
      <font color="#00066f"> 
        A Novel Approach of Decoding EEG Four-Class Motor Imagery Tasks via Scout ESI and CNN
      </font>
    </div>
    <div style="float:right;">
      <a href="https://github.com/SuperBruceJia/EEG-Motor-Imagery-Classification-CNNs-TensorFlow"><i class="fab fa fa-github"></i> Codes</a>
      <a href="https://iopscience.iop.org/article/10.1088/1741-2552/ab4af6/meta"><i class="fab fa fa-file-pdf-o"></i> Paper</a>
    </div><br>
    Yimin Hou, Lu Zhou, <strong>Shuyue Jia</strong>, and Xiangmin Lun
    <em><br>Journal of Neural Engineering</em>, 2020; 17(1):016048.
    <details>
      <summary style="outline:none">See More</summary>
      <ul>
        We presented a novel approach that could potentially be used to improve the current stroke rehabilitation
        strategies by implementing a deep learning approach for an Electroencephalogram (EEG) based on MI Brain-Computer Interface System.
        <ul>
          <li>
		      Constructed 6 convolutional layers, 2 max-pooling layers, and 3 FC layers CNNs for four-class motor 
			  imagery classification through TensorFlow, with 50% dropout (spatial dropout after every Conv layer and regular
			  dropout for FC layers) &ndash; 11.44% accuracy improvement, batch normalization (BN) &ndash; 10.15% improvement, and Short-cut
			  Connection &ndash; 1.76% improvement to prevent overfitting, and achieved SOTA results: 94.50% accuracy on scout R5,
			  94.54% at subject level, and 96% for left fist prediction.
          </li>
          <li>
			  Took charge of DNNs design, including methods comparisons, such as MLPs, CNNs, RNNs, LSTMs, and Autoencoders,
			  classification results calculations, and programming. 10 and 14 subjects&rsquo; data were utilized (19,320 and
			  27,048 samples in the experiments)
          </li>
          <li>
			  Benchmark Dataset: <a href="https://archive.physionet.org/pn4/eegmmidb/"> EEG Motor Movement/Imagery Dataset</a>.
          </li>
        </ul>
        <div>
          <div style="text-align:center">
            <img width="99%device-width" src="./imgs/Picture1.jpg" alt="EEG-CNN">
		  </div>
        </div>
      </ul>
    </details>
  
  </li>
	
<!--  ####################################################################################################################################################-->
  <hr>
  
  <li>
    <div style="float:left;">
      <font color="#00066f">
        GCNs-Net: A Graph Convolutional Neural Network Approach for Decoding Time-resolved EEG Motor Imagery Signals
      </font>
    </div><br>
	<div style="float:left;">
      Xiangmin Lun, <strong>Shuyue Jia *</strong>, Yimin Hou, Yan Shi, and Yang Li
	</div>
	<div style="float:right;">
      <a href="./files/GCNs-Net.pdf"><i class="fa fa-file-powerpoint-o"></i> Presentation</a>
      <a href="./files/Dynamic-GCN-Survey.pdf"><i class="fa fa-file-powerpoint-o"></i> Survey</a>
    </div><br>
	<div style="float:left;">
      <em>arXiv preprint arXiv:2006.08924</em>, 2020.
    </div>
	<div style="float:right;">
      <a href="https://github.com/SuperBruceJia/EEG-DL"><i class="fa fa-github"></i> Codes</a>
      <a href="https://arxiv.org/abs/2006.08924"><i class="fab fa fa-file-pdf-o"></i> Paper</a>
    </div><br><br>
    <details>
      <summary style="outline:none">See More</summary>
      <ul>
        Based on the Graph Convolutional Neural Network (Graph CNN / GCN), the GCNs-Net was introduced, which filtered the EEG Motor
        Imagery (MI) signals considering the functional topological relationship of EEG electrodes.
        <ul>
          <li>
			  At the subject and group level (subject-specific adaptation), 98.72% and 89.387% accuracy were achieved, respectively.
          </li>
          <li>
			  Pearson&rsquo;s Matrix was applied to measure the correlations among channels, and represented the graph structure, i.e., graph weights and degrees.
          </li>
          <li>
			  Benchmark Datasets: <a href="https://archive.physionet.org/pn4/eegmmidb/"> EEG Motor
              Movement/Imagery Dataset</a>, in which 20 ( a million samples), 50, 100 participants&rsquo; data were used, and
			  the <a href="https://gin.g-node.org/robintibor/high-gamma-dataset">High-Gamma Dataset</a>, in which 14 
			  participates' data were used.
          </li>
        </ul>
        <div>
          <div style="text-align:center">
            <img width="99%device-width" src="imgs/Picture2.jpg" alt="Project2">
          </div>
        </div>
      </ul>
    </details>
  </li>

<!--  ####################################################################################################################################################-->
  <hr>

  <li>
    <div style="float:left;">
      <font color="#00066f">Deep Feature Mining via Attention-based BiLSTM-GCN for Human Motor Imagery Recognition</font>
    </div><br>
	<div style="float:left;">
    	Yimin Hou, <strong>Shuyue Jia *</strong>, Xiangmin Lun, Yan Shi, and Yang Li
    </div>
	<div style="float:right;">
		<a href="https://github.com/SuperBruceJia/EEG-DL"><i class="fa fa-github"></i> Codes</a>
		<a href="https://arxiv.org/abs/2005.00777"><i class="fab fa fa-file-pdf-o"></i> Paper</a>
    </div>
    <em><br>arXiv preprint arXiv:2005.00777</em>, 2020.
	<details>
		<summary style="outline:none">See More</summary>
		<ul>
		We introduced a novel approach which combined Attention-based BiLSTM with the Graph Convolutional Neural Network
		(Graph CNN / GCN). The method has achieved SOTA results.
		<ul>
		  <li>
			  Open Source <a href="https://github.com/SuperBruceJia/EEG-DL">EEG-DL</a>, a Deep Learning (DL)
			  library written by TensorFlow for EEG Tasks (Signals) Classification.<br>
		  </li>
		  <li>
			Attention-based BiLSTM was firstly used to extract features from raw EEG signals. The
			followed GCN model classified the features regarding to four EEG Motor Imagery (MI) tasks, imagining left fist, right fist,
			both fists, and both feet.
		  </li>
		  <li>
			98.81% and 94.64% accuracies have been achieved for the individual subject and a group of 20 subjects.
		  </li>
		  <li>
			Benchmark Dataset: <a href="https://archive.physionet.org/pn4/eegmmidb/">EEG Motor Movement/Imagery Dataset</a>.
		  </li>
		</ul>
		<div>
		  <div style="text-align:center">
			<img width="99%device-width" src="./imgs/Picture3.jpg" alt="Project3.1">
			<img width="99%device-width" src="./imgs/Picture4.jpg" alt="Project3.2">
		  </div>
		</div>
	  </ul>
	</details>
  </li>

<!--  ####################################################################################################################################################-->
  <hr>
  
  <li>
    <div style="float:left;">
      <font color="#00066f">
        Attention-based Graph ResNet for Motor Intent Detection from Raw EEG signals
      </font>
    </div><br>
	<div style="float:left;">
    	<strong>Shuyue Jia</strong>, Yimin Hou, Yan Shi, and Yang Li
	</div>
	<div style="float:right;">
      <a href="https://github.com/SuperBruceJia/EEG-DL"><i class="fa fa-github"></i> Codes</a>
      <a href="https://arxiv.org/abs/2007.13484"><i class="fab fa fa-file-pdf-o"></i> Paper</a>
    </div>
    <em><br>arXiv preprint arXiv:2007.13484</em>, 2020.
  </li>

<!--  ####################################################################################################################################################-->
  <hr>
	
  <li>
    <div style="float:left;">
      <font color="#00066f">
        Origin Traceability of Rice based on an Electronic Nose coupled with a Feature Reduction Strategy
        </font>
    </div><br>
    <div style="float:left;">
      Yan Shi, Xiaofei Jia, Hangcheng Yuan, <strong>Shuyue Jia</strong>, Jingjing Liu, and Hong Men
    </div>
    <div style="float:right;">
      <a href="https://iopscience.iop.org/article/10.1088/1361-6501/abb9e7/meta"><i class="fab fa fa-file-pdf-o"></i> Paper</a>
      </div>
    <em><br>Measurement Science and Technology</em>, 2020; 32(2):025107.
  </li>

<!--  ####################################################################################################################################################-->
  <hr>
  
  <li>
    <div style="float:left;">
      <font color="#00066f">
        Improving Performance: a Collaborative Strategy for the Multi-data Fusion of Electronic Nose and Hyperspectral to Track the Quality Difference of Rice
      </font>
    </div><br>
	<div style="float:left;">
    	Yan Shi, Hangcheng Yuan, Chenao Xiong, <strong>Shuyue Jia</strong>, Jingjing Liu, and Hong Men
    </div>
    <div style="float:right;">
      <a href="https://www.sciencedirect.com/science/article/pii/S0925400521001143"><i class="fab fa fa-file-pdf-o"></i> Paper</a>
    </div>
	<em><br>Sensors &amp; Actuators: B. Chemical</em>, 2021; 129546.
  </li>

<!--  ####################################################################################################################################################-->
<hr>
</ol>

<ul><b>* denotes the Corresponding Author.</b></ul>

<!--Academic Services-->
<h2 id="Academic Services">Academic Services</h2>
<ol>
	<li><a href="https://publons.com/researcher/4330829/shuyue-jia/"><strong>Reviewer</strong></a> for <em>IEEE Journal of Biomedical and Health Informatics</em><br></li>
	<li><strong>Student Member</strong> of <em>IEEE</em>, <em>ACM</em>, and <em>CCF</em></li>
</ol>

<!--Previous Awards-->
<h2 id="Selected Awards">Selected Awards</h2>

<ol>
  <li>
    <div style="float:left;">
      <font color="#00066f">
        2019 Interdisciplinary Contest In Modeling
      </font>
    </div>
    <div style="float:right;">
      <a href="./files/ICM-2019.pdf"><i class="fab fa fa-file-pdf-o"></i> Thesis</a>
    </div>
	
    <br>

    <details>
        <summary style="outline:none">Honorable Mention</summary>
          <div>
            <div style="text-align:center">
              <img width="99%device-width" src="./imgs/ICM-2019.jpg" alt="ICM-2019">
            </div>
          </div>
    </details>
  </li>

  <li>
    <div style="float:left;">
      <font color="#00066f">
        2018 Mathematical Contest In Modeling (Jilin, China)
      </font>
    </div>

    <div style="float:right;">
      <a href="./files/MCM-2018.pdf"><i class="fab fa fa-file-pdf-o"></i> Thesis</a>
    </div>
    
    <br>

    <details>
        <summary style="outline:none">First Prize</summary>
          <div>
            <div style="text-align:center">
              <img width="99%device-width" src="./imgs/MCM-2018.jpg" alt="MCM">
            </div>
          </div>
    </details>
  </li>

  <li>
    <div style="float:left;">
      <font color="#00066f">
        2018 Interdisciplinary Contest In Modeling
      </font>
    </div>

    <div style="float:right;">
      <a href="./files/ICM-2018.pdf"><i class="fab fa fa-file-pdf-o"></i> Thesis</a>
    </div>
    
    <br>
    
    <details>
        <summary style="outline:none">Successful Participant</summary>
          <div>
            <div style="text-align:center">
              <img width="99%device-width" src="./imgs/ICM-2018.jpg" alt="ICM-2018">
            </div>
          </div>
    </details>
  </li>
</ol>

<br>
<br>

</div>
</div>
	
<hr>
<br>

</body>
<footer style="text-align:center">
	Last update: Jun 9th, 2021<br>
	<span>Copyright &copy;2020 Shuyue Jia</span>
</footer>
	
<br>
<br>
<br>
<br>
</html>
